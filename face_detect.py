#import tkinter.messagebox
import codecs
#from playsound import playsound
import configparser
import imutils
#from telethon.sync import TelegramClient
import dlib
import numpy as np
import cv2
import os
import pandas as pd
import time
import logging
import smtplib
# Use frontal face detector of Dlib
detector = dlib.get_frontal_face_detector()

# Get face landmarks
predictor = dlib.shape_predictor('data/data_dlib/shape_predictor_68_face_landmarks.dat')

# Use Dlib resnet50 model to get 128D face descriptor
face_reco_model = dlib.face_recognition_model_v1("data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")

config = configparser.ConfigParser()
config.read_file(codecs.open("config.ini", 'r', 'utf8'))

#client = TelegramClient(config['Telegram']['number'], int(config['Telegram']['api_id']), config['Telegram']['api_hash'])


class FaceRecognizer:
    def __init__(self):
        self.font = cv2.FONT_HERSHEY_COMPLEX
        # FPS
        self.frame_time = 0
        self.frame_start_time = 0
        self.fps = 0
        self.fps_show = 0
        self.start_time = time.time()
        # cnt for frame
        self.frame_cnt = 0
        # Save the features of faces in the database
        self.face_features_known_list = []
        #  Save the name of faces in the database
        self.face_name_known_list = []
        #  List to save centroid positions of ROI in frame N-1 and N
        self.last_frame_face_centroid_list = []
        self.current_frame_face_centroid_list = []
        # List to save names of objects in frame N-1 and N
        self.last_frame_face_name_list = []
        self.current_frame_face_name_list = []
        #  cnt for faces in frame N-1 and N
        self.last_frame_face_cnt = 0
        self.current_frame_face_cnt = 0
        #  Save the e-distance for faceX when recognizing
        self.current_frame_face_X_e_distance_list = []
        #  Save the positions and names of current faces captured
        self.current_frame_face_position_list = []
        #  Save the features of people in current frame
        self.current_frame_face_feature_list = []
        # e distance between centroid of ROI in last and current frame
        self.last_current_frame_centroid_e_distance = 0
        # Reclassify after 'reclassify_interval' frames
        self.reclassify_interval_cnt = 0
        self.reclassify_interval = 10
        self.flist_lim = config['Capture']['flist_limit']
        self.pc_unknown = config['Capture']['pc_unknown']
        self.faces = []
        self.quit_key = config['Stream']['quit']

        self.fps_formula = {'Option 1': '1',
                            'Option 2': 'count1 % 10 == 5 or count1 % 10 == 0',
                            'Option 3': 'count1 % 2 == 0'}

    # Get known faces from "features_all.csv"
    def get_face_database(self):
        if os.path.exists("data/features_all.csv"):
            path_features_known_csv = "data/features_all.csv"
            csv_rd = pd.read_csv(path_features_known_csv, header=None)
            for i in range(csv_rd.shape[0]):
                features_someone_arr = []
                self.face_name_known_list.append(csv_rd.iloc[i][0])
                for j in range(1, 129):
                    if csv_rd.iloc[i][j] == '':
                        features_someone_arr.append('0')
                    else:
                        features_someone_arr.append(csv_rd.iloc[i][j])
                self.face_features_known_list.append(features_someone_arr)
            logging.info("Faces in Databaseï¼š %d", len(self.face_features_known_list))
            return 1
        else:
            logging.warning("'features_all.csv' not found!")
            return 0

    def update_fps(self):
        now = time.time()
        # Refresh fps per second
        if str(self.start_time).split(".")[0] != str(now).split(".")[0]:
            self.fps_show = self.fps
        self.start_time = now
        self.frame_time = now - self.frame_start_time
        self.fps = 1.0 / self.frame_time
        self.frame_start_time = now

    @staticmethod
    #  Compute the e-distance between two 128D features
    def return_euclidean_distance(feature_1, feature_2):
        feature_1 = np.array(feature_1)
        feature_2 = np.array(feature_2)
        dist = np.sqrt(np.sum(np.square(feature_1 - feature_2)))
        return dist

    #  Use centroid tracker to link face_x in current frame with person_x in last frame
    def centroid_tracker(self):
        for i in range(len(self.current_frame_face_centroid_list)):
            e_distance_current_frame_person_x_list = []
            # For object 1 in current_frame, compute e-distance with object 1/2/3/4/... in last frame
            for j in range(len(self.last_frame_face_centroid_list)):
                self.last_current_frame_centroid_e_distance = self.return_euclidean_distance(
                    self.current_frame_face_centroid_list[i], self.last_frame_face_centroid_list[j])
                e_distance_current_frame_person_x_list.append(
                    self.last_current_frame_centroid_e_distance)
            last_frame_num = e_distance_current_frame_person_x_list.index(
                min(e_distance_current_frame_person_x_list))
            self.current_frame_face_name_list[i] = self.last_frame_face_name_list[last_frame_num]

    def draw_note(self, img_rd):
        #  Add some info on windows
        cv2.putText(img_rd, f"{config['Text']['frame']}  " + str(self.frame_cnt),
                    (20, 100), self.font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)
        cv2.putText(img_rd, "FPS:    " + str(self.fps.__round__(2)),
                    (20, 130), self.font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)
        cv2.putText(img_rd, f"{config['Text']['faces']}  " + str(self.current_frame_face_cnt),
                    (20, 160), self.font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)
        cv2.putText(img_rd, f"{self.quit_key.upper()}: {config['Text']['exit']}",
                    (20, 450), self.font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)

    def alarm(self, img_rd):
        # c_time = time.ctime()
        # message = f"{config['Text']['alarm_text']}, {c_time}"
        # playsound(config['Sound']['alarm'], block=False)
        # path_tosave = f"{config['Directory']['captured']}{c_time}.jpg"
        # cv2.imwrite(path_tosave, img_rd)
        # tkinter.messagebox.showerror(config['Text']['unknown'], message=message)
        # with client:
        #     client.send_file(config['Telegram']['receiver_nickname'], path_tosave, caption=message)
        # self.faces.clear()

        s = smtplib.SMTP('smtp.gmail.com', 587)
        # start TLS for security
        s.starttls()
        # Authentication
        s.login("2003010057@ipec.org.in", "ASMIT10057")
        # message to be sent
        message = "Tejas is Present"
        # sending the mail
        s.sendmail("2003010057@ipec.org.in", "2003010238@ipec.org.in", message)
        # terminating the session
        s.quit()


    #  Face detection and recognition wit OT from input video stream
    def process(self, stream):
        # 1.  Get faces known from "features.all.csv"
        if self.get_face_database():
            count1 = 0
            while stream.isOpened():
                count1 += 1
                self.frame_cnt += 1
                logging.debug("Frame " + str(self.frame_cnt) + " starts")

                flag, img_rd = stream.read()
                img_rd = imutils.resize(
                                        img_rd,
                                        width=int(config['Stream']['size_w']),
                                        height=int(config['Stream']['size_h'])
                                        )
                kk = cv2.waitKey(1)
                if eval(self.fps_formula[config['Stream']['fps_f']]):
                    # 2.  Detect faces for frame X
                    faces = detector(img_rd, 0)

                    # 3.  / Update cnt for faces in frames
                    self.last_frame_face_cnt = self.current_frame_face_cnt
                    self.current_frame_face_cnt = len(faces)

                    # 4.  Update the face name list in last frame
                    self.last_frame_face_name_list = self.current_frame_face_name_list[:]
                    self.faces += self.last_frame_face_name_list
                    if len(self.faces) > 2 and self.faces[-1] != config['Text']['unknown']:
                        self.faces.remove(self.faces[-2])

                    if len(self.faces) >= int(self.flist_lim):
                        percent = self.faces.count(config['Text']['unknown']) / (len(self.faces) / 100)
                        print(percent)
                        if percent >= int(self.pc_unknown):
                             self.alarm(img_rd)
                        self.faces.clear()

                    # 5.  update frame centroid list
                    self.last_frame_face_centroid_list = self.current_frame_face_centroid_list
                    self.current_frame_face_centroid_list = []

                    # 6.1  if cnt not changes
                    if (self.current_frame_face_cnt == self.last_frame_face_cnt) and (
                            self.reclassify_interval_cnt != self.reclassify_interval):
                        logging.debug("scene 1:  No face cnt changes in this frame!!!")
                        self.current_frame_face_position_list = []
                        if config['Text']['unknown'] in self.current_frame_face_name_list:
                            self.reclassify_interval_cnt += 1

                        if self.current_frame_face_cnt != 0:
                            for k, d in enumerate(faces):
                                self.current_frame_face_position_list.append(tuple(
                                    [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))
                                self.current_frame_face_centroid_list.append(
                                    [int(faces[k].left() + faces[k].right()) / 2,
                                     int(faces[k].top() + faces[k].bottom()) / 2])
                                img_rd = cv2.rectangle(img_rd,
                                                       tuple([d.left(), d.top()]),
                                                       tuple([d.right(), d.bottom()]),
                                                       (255, 255, 255), 2)
                        # Multi-faces in current frame, use centroid-tracker to track
                        if self.current_frame_face_cnt != 1:
                            self.centroid_tracker()
                        for i in range(self.current_frame_face_cnt):
                            # 6.2 Write names under ROI
                            img_rd = cv2.putText(img_rd, self.current_frame_face_name_list[i],
                                                 self.current_frame_face_position_list[i], self.font, 0.8, (0, 255, 255), 1,
                                                 cv2.LINE_AA)
                        self.draw_note(img_rd)

                    # 6.2  If cnt of faces changes, 0->1 or 1->0 or ...
                    else:
                        logging.debug("scene 2:  Faces cnt changes in this frame")
                        self.current_frame_face_position_list = []
                        self.current_frame_face_X_e_distance_list = []
                        self.current_frame_face_feature_list = []
                        self.reclassify_interval_cnt = 0

                        # 6.2.1  Face cnt decreases: 1->0, 2->1, ...
                        if self.current_frame_face_cnt == 0:
                            # clear list of names and features0.
                            self.current_frame_face_name_list = []

                        # 6.2.2 Face cnt increase: 0->1, 0->2, ..., 1->2, ...
                        else:
                            # scene 2.2 Get faces in this frame and do face recognition"
                            self.current_frame_face_name_list = []
                            for i in range(len(faces)):
                                shape = predictor(img_rd, faces[i])
                                self.current_frame_face_feature_list.append(
                                    face_reco_model.compute_face_descriptor(img_rd, shape))
                                self.current_frame_face_name_list.append(config['Text']['unknown'])

                            # 6.2.2.1  Traversal all the faces in the database
                            for k in range(len(faces)):
                                self.current_frame_face_centroid_list.append(
                                    [int(faces[k].left() + faces[k].right()) / 2,
                                     int(faces[k].top() + faces[k].bottom()) / 2])
                                self.current_frame_face_X_e_distance_list = []

                                # 6.2.2.2  Positions of faces captured
                                self.current_frame_face_position_list.append(tuple(
                                    [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))

                                # 6.2.2.3
                                # For every faces detected, compare the faces in the database
                                for i in range(len(self.face_features_known_list)):
                                    if str(self.face_features_known_list[i][0]) != '0.0':
                                        e_distance_tmp = self.return_euclidean_distance(
                                            self.current_frame_face_feature_list[k],
                                            self.face_features_known_list[i])
                                        self.current_frame_face_X_e_distance_list.append(e_distance_tmp)
                                    else:
                                        #  person_X
                                        self.current_frame_face_X_e_distance_list.append(999999999)

                                # 6.2.2.4  Find the one with minimum e distance
                                similar_person_num = self.current_frame_face_X_e_distance_list.index(
                                    min(self.current_frame_face_X_e_distance_list))
                                if min(self.current_frame_face_X_e_distance_list) < 0.4:
                                    self.current_frame_face_name_list[k] = self.face_name_known_list[similar_person_num]

                            # 7.  Add note on cv2 window
                            self.draw_note(img_rd)

                    # Press 'q' to exit
                    if kk == ord(self.quit_key):
                        break
                    self.update_fps()
                    # cv2.namedWindow(self.name_camera, 1)
                    cv2.imshow(f'camera', imutils.resize(img_rd,
                                                         width=int(config['Stream']['window_size_w']),
                                                         height=int(config['Stream']['window_size_h'])))

    def run(self, source):
        cap = cv2.VideoCapture(source)
        self.process(cap)
        cap.release()
        cv2.destroyAllWindows()


def main(source):
    # logging.basicConfig(level=logging.DEBUG)
    # logging.basicConfig(level=logging.INFO)
    face_recogn_con = FaceRecognizer()
    face_recogn_con.run(source=source)


if __name__ == '__main__':
    input = 0  # 0 for webcam, 'rtsp://XXXX' - for rstp-stream, 'https://XXX' for ip-cameras
    main(input)
